{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vusc49_taJfQ"
      },
      "source": [
        "#### imports and variable initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sn9b7-u9aJfS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CxL8tqkeaJfT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import codecs\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import subprocess\n",
        "import os.path\n",
        "import pickle\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Lambda, Activation\n",
        "# from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from tqdm import tqdm\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from numpy import inf\n",
        "from operator import itemgetter\n",
        "\n",
        "seed = 28\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "top_freq_word_to_use = 40000\n",
        "embedding_dimension = 300\n",
        "max_len_head = 25\n",
        "max_len_desc = 50\n",
        "max_length = max_len_head + max_len_desc\n",
        "rnn_layers = 3\n",
        "rnn_size = 600\n",
        "# first 50 numebers from hidden layer output used for\n",
        "# simple context calculation\n",
        "activation_rnn_size = 50\n",
        "\n",
        "empty_tag_location = 0\n",
        "eos_tag_location = 1\n",
        "unknown_tag_location = 2\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#minimum headline should be genrated\n",
        "min_head_line_gen = 10\n",
        "dont_repeat_word_in_last = 5\n",
        "\n",
        "word2vec = []\n",
        "idx2word = {}\n",
        "word2idx = {}\n",
        "# initalize end of sentence, empty and unk tokens\n",
        "word2idx['<empty>'] = empty_tag_location\n",
        "word2idx['<eos>'] = eos_tag_location\n",
        "word2idx['<unk>'] = unknown_tag_location\n",
        "idx2word[empty_tag_location] = '<empty>'\n",
        "idx2word[eos_tag_location] = '<eos>'\n",
        "idx2word[unknown_tag_location] = '<unk>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6iwJnA238ne",
        "outputId": "12ba495c-d62e-4ec7-b83b-aaa441b59cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Word2Vec"
      ],
      "metadata": {
        "id": "9Az_c1jWur3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "pui6SAhsufQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pickle.load(open( \"/content/drive/MyDrive/tokenized_data.pickle\", \"rb\" ) )"
      ],
      "metadata": {
        "id": "JLJvJgH9uxej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NjuTtqCEvQA8",
        "outputId": "761f600b-e34b-4561-edf5-53ee47f9a04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               heads  \\\n",
              "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
              "1  Mentally ill inmates in Miami are housed on th...   \n",
              "2  NEW I thought I was going to die driver says M...   \n",
              "3  Five small polyps found during procedure none ...   \n",
              "4  NEW NFL chief Atlanta Falcons owner critical o...   \n",
              "\n",
              "                                               descs  \n",
              "0  LONDON England Reuters Harry Potter star Danie...  \n",
              "1  Editors note In our Behind the Scenes series C...  \n",
              "2  MINNEAPOLIS Minnesota CNN Drivers who were on ...  \n",
              "3  WASHINGTON CNN Doctors removed five small poly...  \n",
              "4  CNN The National Football League has indefinit...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f819be2c-8281-44fb-8dd1-bf2bac43b762\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>heads</th>\n",
              "      <th>descs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
              "      <td>LONDON England Reuters Harry Potter star Danie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
              "      <td>Editors note In our Behind the Scenes series C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEW I thought I was going to die driver says M...</td>\n",
              "      <td>MINNEAPOLIS Minnesota CNN Drivers who were on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Five small polyps found during procedure none ...</td>\n",
              "      <td>WASHINGTON CNN Doctors removed five small poly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEW NFL chief Atlanta Falcons owner critical o...</td>\n",
              "      <td>CNN The National Football League has indefinit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f819be2c-8281-44fb-8dd1-bf2bac43b762')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f819be2c-8281-44fb-8dd1-bf2bac43b762 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f819be2c-8281-44fb-8dd1-bf2bac43b762');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dafb12d1-0b46-435d-af0a-09296d9d9fb3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dafb12d1-0b46-435d-af0a-09296d9d9fb3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dafb12d1-0b46-435d-af0a-09296d9d9fb3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 60000,\n  \"fields\": [\n    {\n      \"column\": \"heads\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57491,\n        \"samples\": [\n          \"Spike Lees film tells story of AfricanAmerican soldiers during World War II Miracle isnt powerful but muddled and diffuse reviewer writes Movie based on a 2002 novel by James McBride who also wrote screenplay Reviewer Real trouble with Miracle is that Lees filmmaking is joyless\",\n          \"NEW World population could surpass 15 billion by the end of the century the UN says In 1927 the worlds population was 2 billion People under age 25 make up 43 of the current population Africas population is expected to more than triple this century\",\n          \"At least 16 people are dead Italys civil protection agency says Some 14000 people have been displaced by the quakes the agency says Dozens of aftershocks are reported several of more than 50 magnitude The quake struck the same region where seven people were killed nine days ago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57880,\n        \"samples\": [\n          \"CNN It was a remarkably short interview by cable news standards The moment that veteran military reporter Thomas Ricks in an appearance on Fox News begin to unload on Fox he found his segment abruptly ended Thank you very much Nice of you to drop by Adios amigo Some of those who love to dish it out it seems arent very big on taking it The selfprotective shield that some media organizations erect around their companies is hardly limited to Rupert Murdochs network But what happened with Ricks this week is a case study in sidelining a guest who dared challenge the premise of a story To be sure anchor Jon Scott was polite and didnt interrupt Ricks but he couldnt have hustled him off the set faster if he had used a vaudevillestyle hook Watch Should Fox have pulled plug on Tom Ricks for ripping the network Ricks a longtime reporter for the Washington Post and Wall Street Journal has been making the rounds to talk about his latest book The Generals He appeared on Reliable Sources on Sunday and I welcomed his criticism of the media Fox not surprisingly wanted to focus on an issue that it frames as a scandal the Obama administrations handling of the fatal attack on American diplomats in Libya Watch Twitter on fire as Chris Brown slimes a female critic Foxs angle was clear from Scotts setup Right now pressure mounting on the Obama administration over its response to the deadly attack on our consulate in Benghazi But Ricks didnt pull his punches based on the venue I think Benghazi was generally hyped by this network especially he said Scott pushed back which he had every right to do When you have four people dead including the first US ambassador in more than 30 years how do you call that hype Thats when Ricks after explaining the difficulty of determining what happened in a firefight went for the jugular I think that the emphasis on Benghazi has been extremely political partly because Fox was operating as a wing of the Republican Party The interview was over less than 90 seconds after it started Was Ricks being deliberately provocative Perhaps he was for controversy sells books And maybe his criticism was overstated But the fact remains that he was invited as a guest was asked about the Libya attack and responded in a way that made Foxs relentless coverage of the controversy part of the story And that was deemed unacceptable Watch Is it time for Chelsea Clinton gay rights activist to leave NBC Michael Clemente Foxs executive vice president told me that Rickss conduct felt like a stunt That was just bush league especially for a veteran reporter Ricks wasnt answering the anchors question says Clemente and Scott feeling offended decided that Im not going to give this guy any more airtime Whats more Clemente says Ricks apologized to a Fox staffer on the way out Ricks denies this saying he told the staffer who accused him of being rude that he might have been a bit snappish because he was tired from his book tour This was in no way an apology Ricks told me but rather an explanation of why I jumped a bit when the anchor began the segment with the assertion that pressure on the White House was building which it most clearly was not As for the interview itself I was not picking a fight with Fox I was answering their questions Watch Why Matt Lauer is getting a bum rap on Twitter Had Scott wanted to argue that his network was right to pound away at the administrations shifting stories on Libya and that it was the rest of the media that was underplaying the matter they could have had a substantive discussion Instead it was over before it began You have a point Clemente said It could have been a backandforth debate But thats just not Jons style Jon is a more traditional anchorreporter The episode reminded me of an uncomfortable clash in 2010 when Fox anchor Megyn Kelly repeatedly berated Kirsten Powers a liberal contributor to the network for challenging her constant harping on a minor scandal involving the New Black Panther Party Kelly repeatedly interrupted her guest told Powers she didnt know what she was talking about and at one point threatened to cut her mike The difference is that Kelly later realized she had gone too far and told me she had apologized to Powers The anchor of course holds the power in such situations In May MSNBCs Tamron Hall was interviewing Tim Carney a conservative columnist for the Washington Examiner She asked about Mitt Romneys testy reaction to a reporters question the day after a report that the candidate had bullied another student in high school when Carney tried to turn the tables What youre doing here is a typical media trick he said You hype up a story and justify the secondday coverage of the story Hall began lecturing Carney saying you dont have to answer a single question and you didnt have to accept the invitation to come on Youre kind of in my house here as if he were an unruly dinner guest As Carney tried to get a word in Hall kept talking over him Youre irritating me right now Youre not gon na come on and insult me youre not gon na come on and insult the network when you knew what we were gon na talk about Done And he was The anchor went to another guest and Carney had been summarily dismissed for challenging MSNBCs handling of the story Watch Media buzzing as Newt Gingrich says he may run again Whats at issue here is not that onair personalities sometimes let their tempers flare anyone spending many hours on the air including me may get a little peevish now and then Its an attitude that ones own organization is so above reproach that a guests criticism amounts to insulting behavior And since anchors pride themselves on their aggressive questioning they look small and defensive when they shut down the guest Not everyone fits this description of course In fact Foxs Bill OReilly seems to relish the chance to repeat the swipes of anyone who takes him on punch back and invite the offender on for a debate which many decline Cable news can be a rough arena But honest debate even with puglistic guests ought to be a twoway street The opinions expressed in this commentary are solely those of Howard Kurtz\",\n          \"ISTANBUL Turkey CNN Regular programming has just been interrupted by a news conference A slender black man in a suit steps up to a podium flanked by American flags and a White House logo Michael Lamar was laid off in January but has a new job as a Barack Obama lookalike I wish I could announce such an economic package he says but there is a bank in Turkey that did it It is Garanti I wish we had Garanti in America Dont be fooled This is a commercial on Turkish TV The actor is a 44yearold Barack Obama lookalike from Whitehall Pennsylvania named Michael Lamar And he is shilling for a Turkish bank In the month before the real Barack Obama is to visit Turkey this ad campaign went out all across the country on television and on billboards using the iconic Warholian image of the American president to sell lowinterest loans The Mad Men behind the concept say their Obama lookalike was the perfect guy to sell what they described as Garanti Banks own economic stimulus package We probably wouldnt be doing this commercial if it was the previous president said Can Celikbilek a copy writer at the advertising company Alametifarika But in the case of Obama he does represent hope not only for the States but for the whole world For Obama lookalike actor Lamar there was some irony about getting flown to Turkey to star in a commercial for a bank He is a recent casualty of the global economic crisis I was laid off in January of this year from JP Morgan Chase Bank in the US Lamar said in a telephone interview from Pennsylvania After 18 years in the company I was just laid off One of the cutbacks Im currently unemployed right now Or was unemployed Lamars striking resemblance to the American president has suddenly offered the former software analyst a possible new career for supporting his wife and child Im available fulltime now Lamar said Im going to see where this leads me Lamar is now being represented by a casting agency in Los Angeles that specializes in celebrity lookalikes Since he discovered his new talent he has traveled to the Netherlands to appear in a commercial for a liquor chain and to Paris where an activist organization brought him in to meet lawmakers at the National Assembly as part of a campaign to raise awareness about racism and racial profiling in France This was very exciting for me a true privilege Lamar said During his brief visit to Turkey locals did doubletakes when they saw Lamar walk past Even in the studio the crew members were like Oh Is that Obama said Celikbilek of Alametifarika advertising Using the image of an American president to promote anything in Turkey is a remarkable reversal US approval ratings in Turkey plunged to 9 percent according to a 2007 Pew Research poll making America less popular in Turkey then almost anywhere else in the world even though the two countries are NATO allies There was widespread anger among Turks at the war in neighboring Iraq But the election of Barack Obama appears to have dramatically improved perceptions of America Bush was a dictator who attacked other countries said Abdurrahman Ozdemir who sells cigarettes from a small stall on the street But we love Obama because he does not want to go to war with other countries We started to love and like America because of Obama said a 33yearold woman named Begum Arinc I dont want to see people dying I dont want to see any war Thats why I want to believe in Obama\",\n          \"Bogota Colombia CNN Colombian rebels and the government are in exploratory talks to end the countrys nearly 50year armed conflict President Juan Manuel Santos said Monday Speaking on national TV the president said military operations would continue alongside any negotiations with the Revolutionary Armed Forces of Colombia commonly known as the FARC The FARC which has been at war with the Colombian government since the 1960s is Latin Americas oldest insurgency We have developed exploratory talks with the FARC to seek an end to the conflict said Santos whose popularity has suffered because of the widespread perception that security has worsened under his leadership He vowed to avoid the mistakes of the past Colombians can rest assured that the government is acting with prudence seriousness and firmness always putting first the welfare and peace of all residents the president said Santos invited members of a second rebel group the National Liberation Army or ELN to also join in the talks Earlier current and former government sources told CNN that the government and rebels met in Cuba to discuss the possibility of peace Present at the discussions the sources said were members of the FARC and representatives of Santos The sources asked to remain anonymous because they were not authorized to discuss the matter with media Previously on CNNcom Indigenous groups clash with Colombian soldiers The Venezuelan government was reportedly key to bringing the two sides together the sources said Peace talks between the rebels and the government have occurred sporadically since the 1980s The last attempt fell apart in 2002 ThenPresident Andres Pastrana ended negotiations after rebels launched a series of attacks across the country in an apparent bid to strengthen their position Since then the sides have reached a kind of hurting stalemate said Adam Isacson senior associate at the Washington Office on Latin America Though severely weakened in recent years the FARC continues to carry out kidnappings and attack security forces Neither side thinks theyre going to win anytime soon said Isacson What theyre looking at is losing thousands more people with nothing to show for it Of course it remains unclear whether the two sides will reach an agreement at all and if they do what that deal might look like Its also unclear how much of the FARC the groups leadership would be able to deliver said Isacson The FARC opened the door for talks this year In a January statement rebels said they would be interested in addressing certain issues at a hypothetical negotiating table calling on the government to address such subjects as privatization deregulation and environmental degradation The statement was signed by the FARCs leader known as Timoleon Jimenez This conflict will have no solution until our voices are heard Without lies Santos without lies the statement read This spring the FARC freed the last of 10 government hostages after holding them for more than a decade In February the rebel group said it would also stop kidnapping civilians for money It did not address the fate of its civilian captives nor did the group renounce kidnapping for political purposes Hundreds of civilians remain prisoners of the guerrilla group throughout Colombia according to the nonprofit Free Country Foundation The United States and European Union consider the FARC a terrorist organization Boos greet Colombian president in FARC area CNNs Dana Ford Marilia Brocchetto and journalist Fernando Ramos contributed to this report\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "27mAwCLA6hhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)  # Convert text to lowercase and tokenize\n",
        "    # Removed stopwords and punctuation\n",
        "    return tokens\n",
        "\n",
        "# Preprocess the text data in the DataFrame\n",
        "data['processed_text'] = data['descs'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "SYaOnxpo51SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heads are headlines, descs are articles\n",
        "w2v_model = Word2Vec(sentences=data['processed_text'], vector_size=300, window=10, min_count=2, workers=-1)"
      ],
      "metadata": {
        "id": "gG15jEONvYFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = w2v_model.wv\n",
        "word_vectors.save(\"/content/drive/MyDrive/word2vec.wordvectors\")"
      ],
      "metadata": {
        "id": "J5IWKMDr5r-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MReKEp71aJfT"
      },
      "source": [
        "#### read word2vec file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8di-qRkKaJfT"
      },
      "outputs": [],
      "source": [
        "def read_word_embedding(file_name):\n",
        "    \"\"\"\n",
        "    read word embedding file and assign indexes to word\n",
        "    \"\"\"\n",
        "    idx = 3\n",
        "    temp_word2vec_dict = {}\n",
        "    # <empty>, <eos> tag replaced by word2vec learning\n",
        "    # create random dimensional vector for empty, eos and unk tokens\n",
        "    temp_word2vec_dict['<empty>'] = np.random.rand(embedding_dimension, 1)\n",
        "    temp_word2vec_dict['<eos>'] = np.random.rand(embedding_dimension, 1)\n",
        "    temp_word2vec_dict['<unk>'] = np.random.rand(embedding_dimension, 1)\n",
        "    model = gensim.models.KeyedVectors.load(file_name, mmap='r')\n",
        "    V = model.index_to_key\n",
        "    X = np.zeros((top_freq_word_to_use, model.vector_size))\n",
        "    for index, word in enumerate(V):\n",
        "        vector = model[word]\n",
        "        temp_word2vec_dict[idx] = vector\n",
        "        word2idx[word] = idx\n",
        "        idx2word[idx] = word\n",
        "        idx = idx + 1\n",
        "        if idx % 10000 == 0:\n",
        "            print (\"working on word2vec ... idx \", idx)\n",
        "\n",
        "    return temp_word2vec_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Lsmi4PaJfT",
        "outputId": "b7df05b9-70a3-4815-bb08-cb99445afcca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on word2vec ... idx  10000\n",
            "working on word2vec ... idx  20000\n",
            "working on word2vec ... idx  30000\n",
            "working on word2vec ... idx  40000\n",
            "working on word2vec ... idx  50000\n",
            "working on word2vec ... idx  60000\n",
            "working on word2vec ... idx  70000\n",
            "working on word2vec ... idx  80000\n",
            "working on word2vec ... idx  90000\n",
            "working on word2vec ... idx  100000\n",
            "working on word2vec ... idx  110000\n",
            "working on word2vec ... idx  120000\n",
            "working on word2vec ... idx  130000\n",
            "working on word2vec ... idx  140000\n",
            "working on word2vec ... idx  150000\n",
            "working on word2vec ... idx  160000\n",
            "working on word2vec ... idx  170000\n",
            "working on word2vec ... idx  180000\n"
          ]
        }
      ],
      "source": [
        "temp_word2vec_dict = read_word_embedding('/content/drive/MyDrive/word2vec.wordvectors')\n",
        "length_vocab = len(temp_word2vec_dict)\n",
        "shape = (length_vocab, embedding_dimension)\n",
        "# faster initlization and random for <empty> and <eos> tag\n",
        "word2vec = np.random.uniform(low=-1, high=1, size=shape)\n",
        "for i in range(length_vocab):\n",
        "    if i in temp_word2vec_dict:\n",
        "        word2vec[i, :] = temp_word2vec_dict[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP8JX6W2aJfU"
      },
      "source": [
        "#### create model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "regularizer = l2(0)"
      ],
      "metadata": {
        "id": "cgO5_654ILGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j7bQqc_xaJfU"
      },
      "outputs": [],
      "source": [
        "def simple_context(X, mask):\n",
        "    \"\"\"\n",
        "    Simple context calculation layer logic\n",
        "    X = (batch_size, time_steps, units)\n",
        "    time_steps are nothing but number of words in our case.\n",
        "    \"\"\"\n",
        "    # segregrate heading and desc\n",
        "    desc, head = X[:, :max_len_desc, :], X[:, max_len_desc:, :]\n",
        "    # segregrate activation and context part\n",
        "    head_activations, head_words = head[:, :, :activation_rnn_size], head[:, :, activation_rnn_size:]\n",
        "    desc_activations, desc_words = desc[:, :, :activation_rnn_size], desc[:, :, activation_rnn_size:]\n",
        "\n",
        "    # p=(bacth_size, length_desc_words, rnn_units)\n",
        "    # q=(bacth_size, length_headline_words, rnn_units)\n",
        "    # K.dot(p,q) = (bacth_size, length_desc_words,length_headline_words)\n",
        "    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2, 2))\n",
        "\n",
        "    # make sure we dont use description words that are masked out\n",
        "    activation_energies = activation_energies + -1e20 * K.expand_dims(1. - K.cast(mask[:, :max_len_desc], 'float32'), 1)\n",
        "\n",
        "    # for every head word compute weights for every desc word\n",
        "    activation_energies = K.reshape(activation_energies, (-1, max_len_desc))\n",
        "    activation_weights = K.softmax(activation_energies)\n",
        "    activation_weights = K.reshape(activation_weights, (-1, max_len_head, max_len_desc))\n",
        "\n",
        "    # for every head word compute weighted average of desc words\n",
        "    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2, 1))\n",
        "    return K.concatenate((desc_avg_word, head_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1wUCS3LXaJfU"
      },
      "outputs": [],
      "source": [
        "def output_shape_simple_context_layer(input_shape):\n",
        "    \"\"\"\n",
        "    Take input shape tuple and return tuple for output shape\n",
        "    Output shape size for simple context layer =\n",
        "    remaining part after activatoion calculation fron input layers avg. +\n",
        "    remaining part after activatoion calculation fron current hidden layers avg.\n",
        "    that is 2 * (rnn_size - activation_rnn_size))\n",
        "    input_shape[0] = batch_size remains as it is\n",
        "    max_len_head = heading max length allowed\n",
        "    \"\"\"\n",
        "    return (input_shape[0], max_len_head , 2 * (rnn_size - activation_rnn_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L58Ix7vZaJfU"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "        \"\"\"\n",
        "        RNN model creation\n",
        "        Layers include Embedding Layer, 3 LSTM stacked,\n",
        "        Simple Context layer (manually defined),\n",
        "        Time Distributed Layer\n",
        "        \"\"\"\n",
        "        length_vocab, embedding_size = word2vec.shape\n",
        "        print (\"shape of word2vec matrix \", word2vec.shape)\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(\n",
        "                Embedding(\n",
        "                        length_vocab, embedding_size,\n",
        "                        input_length=max_length,\n",
        "                        weights=[word2vec], mask_zero=True,\n",
        "                        name='embedding_layer'\n",
        "                )\n",
        "        )\n",
        "\n",
        "        for i in range(rnn_layers):\n",
        "            lstm = LSTM(rnn_size, return_sequences=True,dropout=0, recurrent_dropout=0,kernel_regularizer=regularizer, recurrent_regularizer=regularizer,\n",
        "                bias_regularizer=regularizer,\n",
        "                name='lstm_layer_%d' % (i + 1)\n",
        "            )\n",
        "\n",
        "            model.add(lstm)\n",
        "            model.add(Dropout(0,name='dropout_%d'%(i+1)))\n",
        "\n",
        "        model.add(Lambda(simple_context,\n",
        "                     mask=lambda inputs, mask: mask[:, max_len_desc:],\n",
        "                     output_shape=output_shape_simple_context_layer,\n",
        "                     name='simple_context_layer'))\n",
        "\n",
        "        vocab_size = word2vec.shape[0]\n",
        "        model.add(TimeDistributed(Dense(vocab_size, kernel_regularizer=regularizer, bias_regularizer=regularizer,\n",
        "                                name='time_distributed_layer')))\n",
        "\n",
        "        model.add(Activation('softmax', name='activation_layer'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "        K.set_value(model.optimizer.lr, np.float32(learning_rate))\n",
        "        print (model.summary())\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02qJaxYYaJfU",
        "outputId": "a0174845-96f3-4f6e-d483-b41fff8900a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of word2vec matrix  (182978, 300)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_layer (Embedding  (None, 75, 300)           54893400  \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_layer_1 (LSTM)         (None, 75, 600)           2162400   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 600)           0         \n",
            "                                                                 \n",
            " lstm_layer_2 (LSTM)         (None, 75, 600)           2882400   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 75, 600)           0         \n",
            "                                                                 \n",
            " lstm_layer_3 (LSTM)         (None, 75, 600)           2882400   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 75, 600)           0         \n",
            "                                                                 \n",
            " simple_context_layer (Lamb  (None, 25, 1100)          0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 25, 182978)        201458778 \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_layer (Activati  (None, 25, 182978)        0         \n",
            " on)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264279378 (1008.15 MB)\n",
            "Trainable params: 264279378 (1008.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZbWH4OnaJfV"
      },
      "source": [
        "## pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "caF6zS_OaJfV"
      },
      "outputs": [],
      "source": [
        "def padding(list_idx, curr_max_length, is_left):\n",
        "    \"\"\"\n",
        "    padds with <empty> tag in left side\n",
        "    \"\"\"\n",
        "    if len(list_idx) >= curr_max_length:\n",
        "        return list_idx\n",
        "    number_of_empty_fill = curr_max_length - len(list_idx)\n",
        "    if is_left:\n",
        "        return [empty_tag_location, ] * number_of_empty_fill + list_idx\n",
        "    else:\n",
        "        return list_idx + [empty_tag_location, ] * number_of_empty_fill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "21Ee27eCaJfV"
      },
      "outputs": [],
      "source": [
        "def headline2idx(list_idx, curr_max_length, is_input):\n",
        "    \"\"\"\n",
        "    if space add <eos> tag in input case, input size = curr_max_length-1\n",
        "    always add <eos> tag in predication case, size = curr_max_length\n",
        "    always right pad\n",
        "    \"\"\"\n",
        "    if is_input:\n",
        "        if len(list_idx) >= curr_max_length - 1:\n",
        "            return list_idx[:curr_max_length - 1]\n",
        "        else:\n",
        "            # space remaning add eos and empty tags\n",
        "            list_idx = list_idx + [eos_tag_location, ]\n",
        "            return padding(list_idx, curr_max_length - 1, False)\n",
        "    else:\n",
        "        # always add <eos>\n",
        "        if len(list_idx) == curr_max_length:\n",
        "            list_idx[-1] = eos_tag_location\n",
        "            return list_idx\n",
        "        else:\n",
        "            # space remaning add eos and empty tags\n",
        "            list_idx = list_idx + [eos_tag_location, ]\n",
        "            return padding(list_idx, curr_max_length, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rbcGdMH6aJfV"
      },
      "outputs": [],
      "source": [
        "def desc2idx(list_idx, curr_max_length):\n",
        "    \"\"\"\n",
        "    always left pad and eos tag to end\n",
        "    \"\"\"\n",
        "    #====== REVERSE THE DESC IDS ========\n",
        "    list_idx.reverse()\n",
        "    # padding to the left remain same and\n",
        "    # eos tag position also remain same,\n",
        "    # just description flipped\n",
        "    #===================================\n",
        "    # desc padded left\n",
        "    list_idx = padding(list_idx, curr_max_length, True)\n",
        "    # eos tag add\n",
        "    list_idx = list_idx + [eos_tag_location, ]\n",
        "    return list_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J6wttZ1CaJfV"
      },
      "outputs": [],
      "source": [
        "def sentence2idx(sentence, is_headline, curr_max_length, is_input=True):\n",
        "    \"\"\"\n",
        "    given a sentence convert it to its ids\n",
        "    \"I like India\" => [12, 51, 102]\n",
        "    if words not present in vocab ignore them\n",
        "    is_input is only for headlines\n",
        "    \"\"\"\n",
        "    list_idx = []\n",
        "    tokens = sentence.split(\" \")\n",
        "    count = 0\n",
        "    for each_token in tokens:\n",
        "        if each_token in word2idx:\n",
        "            list_idx.append(word2idx[each_token])\n",
        "        else:\n",
        "            #append unk token as original word not present in word2vec\n",
        "            list_idx.append(word2idx['<unk>'])\n",
        "        count = count + 1\n",
        "        if count >= curr_max_length:\n",
        "            break\n",
        "\n",
        "    if is_headline:\n",
        "        return headline2idx(list_idx, curr_max_length, is_input)\n",
        "    else:\n",
        "        return desc2idx(list_idx, curr_max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Mvm36gOraJfV"
      },
      "outputs": [],
      "source": [
        "def flip_words_randomly(description_headline_data, number_words_to_replace, model):\n",
        "    \"\"\"\n",
        "    Given actual data i.e. description + eos + headline + eos\n",
        "    1. It predicts news headline (model try to predict, sort of training phase)\n",
        "    2. From actual headline, replace some of the words,\n",
        "    with most probable predication word at that location\n",
        "    3.return description + eos + headline(randomly some replaced words) + eos\n",
        "    (take care of eof and empty should not get replaced)\n",
        "    \"\"\"\n",
        "    if number_words_to_replace <= 0 or model == None:\n",
        "        return description_headline_data\n",
        "\n",
        "    # check all descrption ends with <eos> tag else throw error\n",
        "    assert np.all(description_headline_data[:, max_len_desc] == eos_tag_location)\n",
        "\n",
        "    batch_size = len(description_headline_data)\n",
        "    predicated_headline_word_idx = model.predict(description_headline_data, verbose=1, batch_size = batch_size)\n",
        "    copy_data = description_headline_data.copy()\n",
        "    for idx in range(batch_size):\n",
        "        # description = 0 ... max_len_desc-1\n",
        "        # <eos> = max_len_desc\n",
        "        # headline = max_len_desc + 1 ...\n",
        "        random_flip_pos = sorted(random.sample(range(max_len_desc + 1, max_length), number_words_to_replace))\n",
        "        for replace_idx in random_flip_pos:\n",
        "            # Don't replace <eos> and <empty> tag\n",
        "            if (description_headline_data[idx, replace_idx] == empty_tag_location or\n",
        "            description_headline_data[idx, replace_idx] == eos_tag_location):\n",
        "                continue\n",
        "\n",
        "            # replace_idx offset moving as predication doesnot have desc\n",
        "            new_id = replace_idx - (max_len_desc + 1)\n",
        "            prob_words = predicated_headline_word_idx[idx, new_id]\n",
        "            word_idx = prob_words.argmax()\n",
        "            # dont replace by empty location or eos tag location\n",
        "            if word_idx == empty_tag_location or word_idx == eos_tag_location:\n",
        "                continue\n",
        "            copy_data[idx, replace_idx] = word_idx\n",
        "    return copy_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZIZN3SPkaJfV"
      },
      "outputs": [],
      "source": [
        "def convert_inputs(descriptions, headlines,number_words_to_replace, model,is_training):\n",
        "    \"\"\"\n",
        "    convert input to suitable format\n",
        "    1.Left pad descriptions with <empty> tag\n",
        "    2.Add <eos> tag\n",
        "    3.Right padding with <empty> tag after (desc+headline)\n",
        "    4.input headline doesnot contain <eos> tag\n",
        "    5.expected/predicated headline contain <eos> tag\n",
        "    6.One hot endoing for expected output\n",
        "    \"\"\"\n",
        "    # length of headlines and descriptions should be equal\n",
        "    assert len(descriptions) == len(headlines)\n",
        "\n",
        "    X, y = [], []\n",
        "    for each_desc, each_headline in zip(descriptions, headlines):\n",
        "        input_headline_idx = sentence2idx(each_headline, True, max_len_head, True)\n",
        "        predicted_headline_idx = sentence2idx(each_headline, True, max_len_head, False)\n",
        "        desc_idx = sentence2idx(each_desc, False, max_len_desc)\n",
        "        #print(\"Input headline length\",len(input_headline_idx))\n",
        "        #print(\"Predicted headline length\",len(predicted_headline_idx))\n",
        "        #print(\"Description length\",len(desc_idx))\n",
        "        # assert size checks\n",
        "        assert len(input_headline_idx) == max_len_head - 1\n",
        "        assert len(predicted_headline_idx) == max_len_head\n",
        "        assert len(desc_idx) == max_len_desc + 1\n",
        "\n",
        "        X.append(desc_idx + input_headline_idx)\n",
        "        y.append(predicted_headline_idx)\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    if is_training:\n",
        "        #print(\"Length of X before flipping\",len(X))\n",
        "        X = flip_words_randomly(X, number_words_to_replace, model)\n",
        "        # One hot encoding of y\n",
        "        vocab_size = word2vec.shape[0]\n",
        "        length_of_data = len(headlines)\n",
        "        Y = np.zeros((length_of_data, max_len_head, vocab_size))\n",
        "        for i, each_y in enumerate(y):\n",
        "            Y[i, :, :] = tf.keras.utils.to_categorical(each_y, vocab_size)\n",
        "        #check equal lengths\n",
        "        assert len(X)==len(Y)\n",
        "        return X, Y\n",
        "    else:\n",
        "        #Testing does not require OHE form of headline, flipping also not required\n",
        "        #Because bleu score require words and not OHE form to check accuracy\n",
        "        return X,headlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YIdrGVUzaJfW"
      },
      "outputs": [],
      "source": [
        "def shuffle_file(file_name):\n",
        "    try:\n",
        "        subprocess.check_output(['shuf',file_name,\"--output=\"+file_name])\n",
        "        print (\"Input file shuffled!\")\n",
        "    except:\n",
        "        print (\"Input file NOT shuffled as shuf command not available!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vLHq08mFaJfW"
      },
      "outputs": [],
      "source": [
        "def large_file_reading_generator(data):\n",
        "    \"\"\"\n",
        "    read large file line by line\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        for each_line in data.items():\n",
        "            yield each_line\n",
        "        #shuffle_file(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AV0IK3eaJfW"
      },
      "outputs": [],
      "source": [
        "def data_generator(file_name,number_words_to_replace,model,is_training=True):\n",
        "    \"\"\"\n",
        "    read large file in chunks and return chunk of data to train on\n",
        "    \"\"\"\n",
        "    with open(file_name,'rb') as file_pointer:\n",
        "        data = pickle.load(file_pointer)\n",
        "        headlines_data = data['heads']\n",
        "        descs_data = data['descs']\n",
        "    headline_iterator = large_file_reading_generator(headlines_data)\n",
        "    descs_iterator = large_file_reading_generator(descs_data)\n",
        "    while True:\n",
        "        X, y = [], []\n",
        "        for i in range(16):\n",
        "            heads_line = next(headline_iterator)\n",
        "            descs_line = next(descs_iterator)\n",
        "            heads_line = heads_line[1]\n",
        "            descs_line = descs_line[1]\n",
        "            #print(heads_line)\n",
        "            #print(descs_line)\n",
        "            #headline, desc = each_line.split()\n",
        "            #headline = each_line[0]\n",
        "            #print(headline)\n",
        "            #desc = each_line[1]\n",
        "            #print(desc)\n",
        "            X.append(descs_line)\n",
        "            y.append(heads_line)\n",
        "        #print(y)\n",
        "        yield convert_inputs(X, y, number_words_to_replace, model,is_training)\n",
        "\n",
        "    #numpy_real,numpy_pred = convert_inputs(X, y,number_words_to_replace,model,is_training)\n",
        "    #print(count)\n",
        "    #return numpy_real,numpy_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_WQFDlmaJfW"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bgnBVLTwaJfW"
      },
      "outputs": [],
      "source": [
        "def OHE_to_indexes(y_val):\n",
        "    \"\"\"\n",
        "    reverse of OHE\n",
        "    OHE => indexes\n",
        "    e.g. [[0,0,1],[1,0,0]] => [2,0]\n",
        "    \"\"\"\n",
        "    list_of_headline = []\n",
        "    for each_headline in y_val:\n",
        "        list_of_word_indexes = np.where(np.array(each_headline)==1)[1]\n",
        "        list_of_headline.append(list(list_of_word_indexes))\n",
        "    return list_of_headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fIVDtRpLaJfW"
      },
      "outputs": [],
      "source": [
        "def indexes_to_words(list_of_headline):\n",
        "    \"\"\"\n",
        "    indexes => words (for bleu Score)\n",
        "    e.g. [2,0] => [\"I\",\"am\"] (idx2word defined dictionary used)\n",
        "    \"\"\"\n",
        "    list_of_word_headline = []\n",
        "    for each_headline in list_of_headline:\n",
        "        each_headline_words = []\n",
        "        for each_word in each_headline:\n",
        "            #Dont include <eos> and <empty> tags\n",
        "            if each_word in (empty_tag_location, eos_tag_location, unknown_tag_location):\n",
        "                continue\n",
        "            each_headline_words.append(idx2word[each_word])\n",
        "        list_of_word_headline.append(each_headline_words)\n",
        "    return list_of_word_headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UOaNcm5CaJfW"
      },
      "outputs": [],
      "source": [
        "def bleu_score_text(y_actual,y_predicated):\n",
        "    #check length equal\n",
        "    assert len(y_actual) ==  len(y_predicated)\n",
        "    #list of healine .. each headline has words\n",
        "    no_of_news = len(y_actual)\n",
        "    bleu_score = 0.0\n",
        "    for i in range(no_of_news):\n",
        "        reference = y_actual[i]\n",
        "        hypothesis = y_predicated[i]\n",
        "\n",
        "        #Avoid ZeroDivisionError in bleu score\n",
        "        #default weights\n",
        "        weights=(0.25, 0.25, 0.25, 0.25)\n",
        "        min_len_present = min(len(reference),len(hypothesis))\n",
        "        if min_len_present==0:\n",
        "            continue\n",
        "        if min_len_present<4:\n",
        "            weights=[1.0/min_len_present,]*min_len_present\n",
        "\n",
        "        bleu_score = bleu_score + sentence_bleu([reference],hypothesis,weights=weights)\n",
        "\n",
        "    return bleu_score/float(no_of_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i8V2iPD8aJfW"
      },
      "outputs": [],
      "source": [
        "def bleu_score_calculator(model, validation_file_name, no_of_validation_sample, validation_step_size):\n",
        "    #In validation don't repalce with random words\n",
        "    number_words_to_replace=0\n",
        "    temp_gen = data_generator(validation_file_name,number_words_to_replace, model)\n",
        "\n",
        "    total_bleu_score = 0.0\n",
        "    bleu_batches = 0\n",
        "    bleu_number_of_batches = no_of_validation_sample / validation_step_size\n",
        "    for X_val, y_val in temp_gen:\n",
        "        y_predicated = model.predict_classes(X_val,batch_size = validation_step_size,verbose = 1)\n",
        "        y_predicated_words = indexes_to_words(y_predicated)\n",
        "        list_of_word_headline = indexes_to_words(OHE_to_indexes(y_val))\n",
        "        assert len(y_val)==len(list_of_word_headline)\n",
        "\n",
        "        total_bleu_score = total_bleu_score + bleu_score_text(list_of_word_headline, y_predicated_words)\n",
        "\n",
        "        bleu_batches += 1\n",
        "        if bleu_batches >=  bleu_number_of_batches:\n",
        "            #get out of infinite loop of val generator\n",
        "            break\n",
        "        if bleu_batches%10==0:\n",
        "            print (\"eval for {} out of {}\".format(bleu_batches, bleu_number_of_batches))\n",
        "\n",
        "    #close files and delete generator\n",
        "    del temp_gen\n",
        "    return total_bleu_score/float(bleu_batches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-ovncqhVaJfX"
      },
      "outputs": [],
      "source": [
        "def train(model,data_file,val_file,train_size,val_size,val_step_size,epochs,words_replace_count,model_weights_file_name):\n",
        "    \"\"\"\n",
        "    trains a model\n",
        "    Manually loop (without using internal epoch parameter of keras),\n",
        "    train model for each epoch, evaluate logloss and bleu score of model on validation data\n",
        "    save model if bleu/logloss score improvement ...\n",
        "    save score history for plotting purposes.\n",
        "    Note : validation step size meaning over here is different from keras\n",
        "    here validation_step_size means, batch_size in which bleu score evaluated\n",
        "    after all batches processed, bleu scores over all batches averaged to get one bleu score.\n",
        "    \"\"\"\n",
        "    #load model weights if file present\n",
        "    if os.path.isfile(model_weights_file_name):\n",
        "        print (\"loading weights already present in {}\".format(model_weights_file_name))\n",
        "        model.load_weights(model_weights_file_name)\n",
        "        print (\"model weights loaded for further training\")\n",
        "\n",
        "    train_data = data_generator(data_file,words_replace_count, model)\n",
        "    #print(train_data)\n",
        "    bleu_scores = []\n",
        "    #bleu score are always greater than 0\n",
        "    best_bleu_score_track = -1.0\n",
        "    number_of_batches = math.ceil(train_size / float(16))\n",
        "\n",
        "    for each_epoch in range(epochs):\n",
        "        print (\"running for epoch \",each_epoch)\n",
        "        start_time = time.time()\n",
        "        #print(start_time)\n",
        "        #manually loop over batches and feed to network\n",
        "        #purposefully not used fit_generator\n",
        "        batches = 0\n",
        "        for X_batch, Y_batch in train_data:\n",
        "            #print(\"Inside train_data generated\")\n",
        "            #print(X_batch)\n",
        "            #print('------------------------')\n",
        "            #print(Y_batch)\n",
        "            model.fit(X_batch,Y_batch,batch_size=16,epochs=1)\n",
        "            batches += 1\n",
        "            #take last chunk and roll over to start ...\n",
        "            #therefore float used ...\n",
        "            if batches >= number_of_batches :\n",
        "                break\n",
        "            if batches%10==0:\n",
        "                print (\"training for {} out of {} for epoch {}\".format(batches, number_of_batches, each_epoch))\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(\"time to train epoch \",end_time-start_time)\n",
        "\n",
        "        # evaluate model on bleu score and save best bleu score model...\n",
        "        bleu_score_now = bleu_score_calculator(model,val_file,val_size,val_step_size)\n",
        "        bleu_scores.append(bleu_score_now)\n",
        "        if best_bleu_score_track < bleu_score_now:\n",
        "            best_bleu_score_track = bleu_score_now\n",
        "            print (\"saving model for bleu score \",best_bleu_score_track)\n",
        "            model.save_weights(model_weights_file_name)\n",
        "\n",
        "        # Note : It saves on every loop, this looks REPETITIVE, BUT\n",
        "        # if user aborts in middle of epochs then we get previous\n",
        "        # present history\n",
        "        # User can track previous history while model running ...\n",
        "        # dump history object list for further plotting of loss\n",
        "        # append bleu Score for to another list  and dump for futher plotting\n",
        "        with open(\"bleu_scores.pickle\", \"wb\") as output_file:\n",
        "            pickle.dump(bleu_scores, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training starts"
      ],
      "metadata": {
        "id": "HRJH1j7gS0Wf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZjeeKc1aJfX",
        "outputId": "6cc934bc-e899-4d04-bd60-8764662e7217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running for epoch  0\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "1/1 [==============================] - 37s 37s/step - loss: 12.1172\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 12.1144\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 12.1112\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 12.1067\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 12.0999\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 12.0914\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 12.0674\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 12.0418\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 12.0171\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 11.9612\n",
            "training for 10 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 11.8817\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 11.7797\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 11.7380\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 11.6447\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 11.5682\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 11.4610\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 11.3722\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 25s 25s/step - loss: 11.2795\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 11.1423\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 11.0330\n",
            "training for 20 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 10.8761\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 22s 22s/step - loss: 10.7312\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 10.6532\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 22s 22s/step - loss: 10.5193\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 10.3831\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 10.2675\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 9.9473\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 9.8817\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 9.4618\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 9.6511\n",
            "training for 30 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 9.4214\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 25s 25s/step - loss: 9.2895\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 8.9778\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.9990\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 18s 18s/step - loss: 8.9375\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.8919\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 8.5948\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.4562\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 8.1271\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.1402\n",
            "training for 40 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.8637\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.0639\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 8.2231\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.9246\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 8.0481\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.6763\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.8488\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.4237\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.8506\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.5792\n",
            "training for 50 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 27s 27s/step - loss: 7.3671\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.2214\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.2413\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4295\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.4564\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.7617\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.5273\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4781\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.3567\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 22s 22s/step - loss: 7.2916\n",
            "training for 60 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.5147\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4525\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.2235\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.4346\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.3659\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.7212\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 23s 23s/step - loss: 7.3448\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.2039\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.4701\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.5915\n",
            "training for 70 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.1437\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.7474\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.5418\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.3459\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.6211\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.2021\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.3940\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 18s 18s/step - loss: 7.4754\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.1233\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4740\n",
            "training for 80 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.7515\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.1771\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.1356\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.5211\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4245\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.3131\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.0783\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.5576\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.6494\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.2873\n",
            "training for 90 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.1197\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 18s 18s/step - loss: 7.4019\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.6085\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.7078\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.8747\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.7196\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.8701\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.1062\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.6220\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.3952\n",
            "training for 100 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4392\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.3371\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.1298\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.6356\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.5240\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4505\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.6747\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.2944\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 19s 19s/step - loss: 7.4815\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.4465\n",
            "training for 110 out of 3125 for epoch 0\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.4592\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.2405\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.7656\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 6.9901\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 20s 20s/step - loss: 7.2662\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.5050\n",
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        }
      ],
      "source": [
        "train(model=model,\n",
        "    data_file='/content/drive/MyDrive/train_data.pickle',\n",
        "    val_file='/content/drive/MyDrive/val_data.pickle',\n",
        "    train_size=50000,\n",
        "    val_size=5000,\n",
        "    val_step_size=32,\n",
        "    epochs=5,\n",
        "    words_replace_count=5,\n",
        "    model_weights_file_name='model_weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam search and testing"
      ],
      "metadata": {
        "id": "-uVJI0soS51G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wQv99vhxaJfX"
      },
      "outputs": [],
      "source": [
        "def is_headline_end(word_index_list,current_predication_position):\n",
        "    \"\"\"\n",
        "    is headline ended checker\n",
        "    current_predication_position is 0 index based\n",
        "    \"\"\"\n",
        "    if (word_index_list is None) or (len(word_index_list)==0):\n",
        "        return False\n",
        "    if word_index_list[current_predication_position]==eos_tag_location or current_predication_position>=max_length:\n",
        "        return True\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gCcLjQleaJfX"
      },
      "outputs": [],
      "source": [
        "def process_word(predication,word_position_index,top_k,X,prev_layer_log_prob):\n",
        "    \"\"\"\n",
        "    Extract top k predications of given position\n",
        "    \"\"\"\n",
        "    #predication conttains only one element\n",
        "    #shape of predication (1,max_head_line_words,vocab_size)\n",
        "    predication = predication[0]\n",
        "    #predication (max_head_line_words,vocab_size)\n",
        "    predication_at_word_index = predication[word_position_index]\n",
        "    sorted_arg = predication_at_word_index.argsort()\n",
        "    top_probable_indexes = sorted_arg[::-1]\n",
        "    top_probabilities = np.take(predication_at_word_index,top_probable_indexes)\n",
        "    log_probabilities = np.log(top_probabilities)\n",
        "    #make sure elements doesnot contain -infinity\n",
        "    log_probabilities[log_probabilities == -inf] = -sys.maxsize - 1\n",
        "    #add prev layer probability\n",
        "    log_probabilities = log_probabilities + prev_layer_log_prob\n",
        "    assert len(log_probabilities)==len(top_probable_indexes)\n",
        "\n",
        "    #add previous words ... preparation for next input\n",
        "    #offset calculate ... description + eos + headline till now\n",
        "    offset = max_len_desc+word_position_index+1\n",
        "    ans = []\n",
        "    count = 0\n",
        "    for i,j in zip(log_probabilities, top_probable_indexes):\n",
        "        #check for word should not repeat in headline ...\n",
        "        #checking for last x words, where x = dont_repeat_word_in_last\n",
        "        if j in X[max_len_desc+1:offset][-dont_repeat_word_in_last:]:\n",
        "            continue\n",
        "        if (word_position_index < min_head_line_gen) and (j in [empty_tag_location, unknown_tag_location, eos_tag_location]):\n",
        "            continue\n",
        "\n",
        "        next_input = np.concatenate((X[:offset], [j,]))\n",
        "        next_input = next_input.reshape((1,next_input.shape[0]))\n",
        "        #for the last time last word put at max_length + 1 position\n",
        "        #don't truncate that\n",
        "        if offset!=max_length:\n",
        "            next_input = sequence.pad_sequences(next_input, maxlen=max_length, value=empty_tag_location, padding='post', truncating='post')\n",
        "        next_input = next_input[0]\n",
        "        ans.append((i,next_input))\n",
        "        count = count + 1\n",
        "        if count>=top_k:\n",
        "            break\n",
        "    #[(prob,list_of_words_as_next_input),(prob2,list_of_words_as_next_input2),...]\n",
        "    return ans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bDihlNHUaJfX"
      },
      "outputs": [],
      "source": [
        "def beam_search(model,X,top_k):\n",
        "    \"\"\"\n",
        "    1.Loop over max headline word allowed\n",
        "    2.predict word prob and select top k words for each position\n",
        "    3.select top probable combination uptil now for next round\n",
        "    \"\"\"\n",
        "    #contains [(log_p untill now, word_seq), (log_p2, word_seq2)]\n",
        "    prev_word_index_top_k = []\n",
        "    curr_word_index_top_k = []\n",
        "    done_with_pred = []\n",
        "    #1d => 2d array [1,2,3] => [[1,2,3]]\n",
        "    data = X.reshape((1,X.shape[0]))\n",
        "    #shape of predication (1,max_head_line_words,vocab_size)\n",
        "    predication = model.predict_proba(data,verbose=0)\n",
        "    #prev layer probability 1 => np.log(0)=0.0\n",
        "    prev_word_index_top_k = process_word(predication,0,top_k,X,0.0)\n",
        "\n",
        "    #1st time its done above to fill prev word therefore started from 1\n",
        "    for i in range(1,max_len_head):\n",
        "        #i = represents current intrested layer ...\n",
        "        for j in range(len(prev_word_index_top_k)):\n",
        "            #j = each time loops for top k results ...\n",
        "            probability_now, current_intput = prev_word_index_top_k[j]\n",
        "            data = current_intput.reshape((1,current_intput.shape[0]))\n",
        "            predication = model.predict_proba(data,verbose=0)\n",
        "            next_top_k_for_curr_word = process_word(predication,i,top_k,current_intput,probability_now)\n",
        "            curr_word_index_top_k = curr_word_index_top_k + next_top_k_for_curr_word\n",
        "\n",
        "        #sort new list, empty old, copy top k element to old, empty new\n",
        "        curr_word_index_top_k = sorted(curr_word_index_top_k,key=itemgetter(0),reverse=True)\n",
        "        prev_word_index_top_k_temp = curr_word_index_top_k[:top_k]\n",
        "        curr_word_index_top_k = []\n",
        "        prev_word_index_top_k = []\n",
        "        #if word predication eos ... put it done list ...\n",
        "        for each_proba, each_word_idx_list in prev_word_index_top_k_temp:\n",
        "            offset = max_len_desc+i+1\n",
        "            if is_headline_end(each_word_idx_list,offset):\n",
        "                done_with_pred.append((each_proba, each_word_idx_list))\n",
        "            else:\n",
        "                prev_word_index_top_k.append((each_proba,each_word_idx_list))\n",
        "\n",
        "    #sort according to most probable\n",
        "    done_with_pred = sorted(done_with_pred,key=itemgetter(0),reverse=True)\n",
        "    done_with_pred = done_with_pred[:top_k]\n",
        "    return done_with_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LYIm8Gl2aJfX"
      },
      "outputs": [],
      "source": [
        "def test(model, data_file_name, no_of_testing_sample, model_weights_file_name,top_k,output_file,seperator='#|#'):\n",
        "    \"\"\"\n",
        "    test on given description data file with empty headline ...\n",
        "    \"\"\"\n",
        "    model.load_weights(model_weights_file_name)\n",
        "    print (\"model weights loaded\")\n",
        "    #Always 1 for now ... later batch code for test sample created\n",
        "    test_batch_size = 1\n",
        "    test_data_generator = data_generator(data_file_name, number_words_to_replace=0, model=None,is_training=False)\n",
        "    number_of_batches = math.ceil(no_of_testing_sample / float(test_batch_size))\n",
        "\n",
        "    with codecs.open(output_file, 'w',encoding='utf8') as f:\n",
        "        #testing batches\n",
        "        batches = 0\n",
        "        for X_batch, Y_batch in test_data_generator:\n",
        "            #Always come one because X_batch contains one element\n",
        "            X = X_batch[0]\n",
        "            Y = Y_batch[0]\n",
        "            assert X[max_len_desc]==eos_tag_location\n",
        "            #wipe up news headlines present and replace by empty tag ...\n",
        "            X[max_len_desc+1:]=empty_tag_location\n",
        "            result = beam_search(model,X,top_k)\n",
        "            #take top most probable element\n",
        "            list_of_word_indexes = result[0][1]\n",
        "            list_of_words = indexes_to_words([list_of_word_indexes])[0]\n",
        "            headline = u\" \".join(list_of_words[max_len_desc+1:])\n",
        "            f.write(Y+seperator+headline+\"\\n\")\n",
        "            batches += 1\n",
        "            #take last chunk and roll over to start ...\n",
        "            #therefore float used ...\n",
        "            if batches >= number_of_batches :\n",
        "                break\n",
        "            if batches%10==0:\n",
        "                print (\"working on batch no {} out of {}\".format(batches,number_of_batches))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vltldu6naJfY"
      },
      "outputs": [],
      "source": [
        "test(model=model,\n",
        "    data_file_name='test_data.pkl',\n",
        "    no_of_testing_sample= 12567,\n",
        "    model_weights_file_name='model_weights.h5',\n",
        "    top_k=5,\n",
        "    output_file='test_output.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google news 300 dim word2vec model"
      ],
      "metadata": {
        "id": "5y63-Cwt4Hb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmodel = model = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True,l)"
      ],
      "metadata": {
        "id": "0w2e_QygFTWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test output for a LSTM model trained using Google news negative 300 word-vectors:\n",
        "\n",
        "- DNC email leaks explained#|# <br>\n",
        "- Anyone who thinks Trump was just joking about shooting Clinton is missing the point#|#Trump The New York Times <br>\n",
        "- Carly Rae Jepsens Emotion Side B is the latebreaking soundtrack of summer#|#<br>\n",
        "- The problem with all the speculation about Hillary Clintons pneumonia#|#The New York Times in The New York Times<br>\n",
        "- A plea for sanity — and seriousness — in judging the debate#|#<br>\n",
        "- 61 insults 39 women Trumps long history of misogyny#|#Times"
      ],
      "metadata": {
        "id": "gV5oEa30aWl5"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}